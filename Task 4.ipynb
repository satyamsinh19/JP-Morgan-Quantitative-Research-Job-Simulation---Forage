{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24186d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FICO_min  FICO_max  Count  Defaults  Default_rate\n",
      "0       408       520    301       199        0.6611\n",
      "1       521       580   1407       536        0.3810\n",
      "2       581       640   3438       703        0.2045\n",
      "3       641       696   3197       336        0.1051\n",
      "4       697       850   1657        77        0.0465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\satya\\Downloads\\QR - JP Morgan\\Task 3 and 4_Loan_Data.csv\")\n",
    "\n",
    "# Extract relevant columns\n",
    "fico = df['fico_score'].astype(int).to_list()\n",
    "defaults = df['default'].astype(int).to_list()\n",
    "n = len(fico)\n",
    "\n",
    "# Aggregate by unique FICO score\n",
    "data = pd.DataFrame({'fico': fico, 'default': defaults})\n",
    "agg = data.groupby('fico').agg(total=('default', 'size'),\n",
    "                               defaults=('default', 'sum')).reset_index().sort_values('fico')\n",
    "\n",
    "scores = agg['fico'].to_list()\n",
    "total = agg['total'].to_list()\n",
    "default = agg['defaults'].to_list()\n",
    "m = len(scores)\n",
    "\n",
    "# Prefix sums\n",
    "prefix_total = np.cumsum(total)\n",
    "prefix_default = np.cumsum(default)\n",
    "\n",
    "# Log-likelihood function\n",
    "def log_likelihood(n, k):\n",
    "    if n == 0: return 0\n",
    "    p = k / n\n",
    "    if p <= 0 or p >= 1:\n",
    "        return 0\n",
    "    return k * log(p) + (n - k) * log(1 - p)\n",
    "\n",
    "# Dynamic programming approach for K buckets\n",
    "K = 5\n",
    "dp = np.full((K+1, m), -1e18)\n",
    "prev = np.full((K+1, m), -1, dtype=int)\n",
    "\n",
    "for j in range(m):\n",
    "    dp[1, j] = log_likelihood(prefix_total[j], prefix_default[j])\n",
    "\n",
    "for k in range(2, K+1):\n",
    "    for j in range(k-1, m):\n",
    "        for t in range(k-2, j):\n",
    "            n_bucket = prefix_total[j] - prefix_total[t]\n",
    "            k_bucket = prefix_default[j] - prefix_default[t]\n",
    "            ll = log_likelihood(n_bucket, k_bucket)\n",
    "            val = dp[k-1, t] + ll\n",
    "            if val > dp[k, j]:\n",
    "                dp[k, j] = val\n",
    "                prev[k, j] = t\n",
    "\n",
    "# Reconstruct boundaries\n",
    "cuts = []\n",
    "k = K\n",
    "j = m - 1\n",
    "while k > 0:\n",
    "    t = prev[k, j]\n",
    "    cuts.append((t+1, j))\n",
    "    j = t\n",
    "    k -= 1\n",
    "cuts = cuts[::-1]\n",
    "\n",
    "# Create summary table\n",
    "boundaries = []\n",
    "for (i, j) in cuts:\n",
    "    low = scores[i]\n",
    "    high = scores[j]\n",
    "    cnt = prefix_total[j] - (prefix_total[i-1] if i > 0 else 0)\n",
    "    defs = prefix_default[j] - (prefix_default[i-1] if i > 0 else 0)\n",
    "    rate = defs / cnt\n",
    "    boundaries.append([low, high, cnt, defs, round(rate, 4)])\n",
    "\n",
    "buckets = pd.DataFrame(boundaries, columns=['FICO_min', 'FICO_max', 'Count', 'Defaults', 'Default_rate'])\n",
    "print(buckets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37db43b",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The objective is to quantize continuous FICO scores into discrete “rating buckets” that summarize borrower credit risk. \n",
    "A lower rating indicates a better credit score, while a higher rating represents higher risk.\n",
    "\n",
    "This task is a discretization problem optimized by maximizing the log-likelihood function:\n",
    "\n",
    "L = Σ [kᵢ log(pᵢ) + (nᵢ - kᵢ) log(1 - pᵢ)]\n",
    "\n",
    "where kᵢ is the number of defaults in bucket i, nᵢ is the total records in bucket i, and pᵢ = kᵢ/nᵢ is the probability \n",
    "of default within the bucket.\n",
    "\n",
    "\n",
    "To find the optimal bucket boundaries, a dynamic programming (DP) approach is used. DP iteratively determines where \n",
    "to split the FICO score range to maximize total log-likelihood. The algorithm runs in O(K × N²) time, where K is \n",
    "the number of desired buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46390490",
   "metadata": {},
   "source": [
    "### Results\n",
    "| Rating     | FICO Range | Count | Defaults | Default Rate |\n",
    "|:-----------|:------------|------:|----------:|--------------:|\n",
    "| 0 (worst)  | 408 – 520   | 301   | 199       | 0.6611 |\n",
    "| 1           | 521 – 580   | 1,407 | 536       | 0.3810 |\n",
    "| 2           | 581 – 640   | 3,438 | 703       | 0.2045 |\n",
    "| 3           | 641 – 696   | 3,197 | 336       | 0.1051 |\n",
    "| 4 (best)   | 697 – 850   | 1,657 | 77        | 0.0465 |\n",
    "\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- *Borrowers in the highest bucket (697–850) have the lowest probability of default (~4.7%), indicating strong creditworthiness.*\n",
    "- *Borrowers in the lowest bucket (408–520) show very high default risk (~66%), signifying poor credit quality.*\n",
    "- *This structure can serve as a rating map for assigning risk grades in future datasets.*\n",
    "\n",
    "\n",
    "\n",
    "### Rating Map\n",
    "\n",
    "| Rating | FICO Range | Credit Category |\n",
    "|:------:|:------------|:----------------|\n",
    "| 4 | 697–850 | Excellent |\n",
    "| 3 | 641–696 | Good |\n",
    "| 2 | 581–640 | Fair |\n",
    "| 1 | 521–580 | Poor |\n",
    "| 0 | 408–520 | Very Poor |\n",
    "\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This analysis builds a quantization framework for FICO scores using a log-likelihood–based dynamic programming method.\n",
    "It optimally partitions borrower credit scores into risk-based buckets, producing clear, data-driven rating boundaries.\n",
    "The log-likelihood approach is preferred here over MSE because it explicitly models default probabilities, which aligns \n",
    "directly with credit risk prediction goals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
